{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "''' Concatenate the contents of all files in the data folder into one single text file named full.txt. '''\n",
    "def concat_files():\n",
    "    with open('full.txt', 'w', encoding='utf8') as f:\n",
    "        for file in os.listdir('data'):\n",
    "            with open(os.path.join('data', file), encoding='utf8') as g:\n",
    "                f.write(g.read())\n",
    "\n",
    "concat_files()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sp.SentencePieceTrainer.train(input='full.txt', model_prefix='m_en_de', vocab_size=15000, model_type='unigram', character_coverage=1.0, input_sentence_size=10000000, shuffle_input_sentence=True, max_sentence_length=1000, num_threads=16, unk_id=0, bos_id=1, eos_id=2, pad_id=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Chen Zerui\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def subsequent_mask(size):\n",
    "    \"Mask out subsequent positions.\"\n",
    "    attn_shape = (1, size, size)\n",
    "    subsequent_mask = np.tril(np.ones(attn_shape)).astype('uint8')\n",
    "    return torch.from_numpy(subsequent_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1, 0, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 0, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 0, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 0, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 0, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 0, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 0, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 0, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 0],\n",
       "         [1, 1, 1, 1, 1, 1, 1, 1, 1, 1]]], dtype=torch.uint8)"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "subsequent_mask(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([  -0.9382,   -0.9382,   -1.8765,   -2.8147,   -4.6912,   -7.5059,\n",
       "          -12.1971,  -19.7030,  -31.9001,  -51.6031,  -83.5033, -135.1064,\n",
       "         -218.6097, -353.7161, -572.3258, -926.0419]),\n",
       " tensor([-9.3824e-01, -1.8765e+00, -2.8147e+00, -4.6912e+00, -7.5059e+00,\n",
       "         -1.2197e+01, -1.9703e+01, -3.1900e+01, -5.1603e+01, -8.3503e+01,\n",
       "         -1.3511e+02, -2.1861e+02, -3.5372e+02, -5.7233e+02, -9.2604e+02,\n",
       "         -1.4984e+03]))"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "class FibonacciDataset(torch.utils.data.Dataset):\n",
    "    \n",
    "\t''' A toy dataset that generates pairs of fibonaci sequences starting at a random float between -1 and 1.\n",
    "\tThe second sequence is the first sequence shifted by one position to the right.\n",
    "\t '''\n",
    "\n",
    "\tdef __init__(self, block_size=16):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.block_size = block_size\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tstart = np.random.uniform(-1, 1)\n",
    "\t\tfib = [start, start]\n",
    "\t\tfor i in range(self.block_size - 1):\n",
    "\t\t\tfib.append(fib[-1] + fib[-2])\n",
    "\t\tx = torch.tensor(fib[:-1], dtype=torch.float32)\n",
    "\t\ty = torch.tensor(fib[1:], dtype=torch.float32)\n",
    "\t\treturn x, y\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn 10000000000000\n",
    "\n",
    "FibonacciDataset()[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [],
   "source": [
    "class ReversionDataset(torch.utils.data.Dataset):\n",
    "\t\n",
    "\t''' A toy dataset that generates pairs of sequences, where the second sequence is the first sequence reversed.\n",
    "\t '''\n",
    "\n",
    "\tdef __init__(self, block_size=16):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.block_size = block_size\n",
    "\n",
    "\tdef __getitem__(self, idx):\n",
    "\t\tx = torch.randint(0, 10, (self.block_size,), dtype=torch.float32)\n",
    "\t\ty = x.flip(0)\n",
    "\t\treturn x, y\n",
    "\t\n",
    "\tdef __len__(self):\n",
    "\t\treturn 10000000000000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch import nn, Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "class InputEmbeddings(nn.Module):\n",
    "\t''' Apply learnable token and position embeddings to input tokens. '''\n",
    "\n",
    "\tdef __init__(self, vocab_size: int, emb_dim: int, block_size: int):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.token_embedding_table = nn.Embedding(vocab_size, emb_dim)\n",
    "\t\tself.position_embedding_table = nn.Embedding(block_size, emb_dim)\n",
    "\t\tself.register_buffer('pos_emb_index', torch.arange(block_size))\n",
    "\t\n",
    "\tdef forward(self, x: Tensor):\n",
    "\t\tB, T = x.shape\n",
    "\t\ttok_embd = self.token_embedding_table(x)\n",
    "\t\tpos_embd = self.position_embedding_table(self.pos_emb_index[:T])\n",
    "\t\treturn tok_embd + pos_embd\n",
    "\n",
    "class MultiHeadSelfAttention(nn.Module):\n",
    "\n",
    "\t''' Multi-head self attention.\n",
    "\tImplements a somewhat optimized version of the self attention by combining the q, k, v projections.\n",
    "\t\n",
    "\tInputs:\n",
    "\t\tx: input tensor of shape (B, T, C)\n",
    "\t\tmask: mask tensor of shape broadcastable to (B, T, T)\n",
    "\t'''\n",
    "\n",
    "\tdef __init__(self, n_heads: int, emb_dim: int, bias: bool, block_size: int, is_causal: bool = False):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.is_causal = is_causal\n",
    "\t\tself.n_heads = n_heads\n",
    "\t\tself.emb_dim = emb_dim\n",
    "\t\t# combine q, k, v projections for efficiency\n",
    "\t\tself.qkv_projection = nn.Linear(emb_dim, 3 * emb_dim, bias=bias)\n",
    "\t\tself.register_buffer('scale', torch.tensor(emb_dim ** -0.5, dtype=torch.float32))\n",
    "\t\tif is_causal:\n",
    "\t\t\tself.register_buffer('causal_mask', torch.tril(torch.ones(1, block_size, block_size, dtype=torch.bool)))\n",
    "\n",
    "\tdef forward(self, x: Tensor, mask: Tensor, return_attentions: bool = False):\n",
    "\t\tB, T, C = x.shape\n",
    "\t\t# proj q, k, v for all heads\n",
    "\t\t# the heads are treated as a batch dimension\n",
    "\t\tq, k, v = self.qkv_projection(x).split(self.emb_dim, dim=2)\n",
    "\t\tq = q.view(B, T, self.n_heads, C // self.n_heads).transpose(1, 2)\n",
    "\t\tk = k.view(B, T, self.n_heads, C // self.n_heads).transpose(1, 2)\n",
    "\t\tv = v.view(B, T, self.n_heads, C // self.n_heads).transpose(1, 2)\n",
    "\t\t# compute attention\n",
    "\t\tatt_weights = (q @ k.transpose(-2, -1)) / self.scale\n",
    "\t\tmask = mask.unsqueeze(1) # apply mask over all heads\n",
    "\t\tif self.is_causal:\n",
    "\t\t\tmask = mask & self.causal_mask[:, :T, :T]\n",
    "\t\tatt_weights = att_weights.masked_fill(mask == 0, -1e9)\n",
    "\t\tatt_weights = F.softmax(att_weights, dim=-1)\n",
    "\t\ty = att_weights @ v\n",
    "\t\t# combine heads\n",
    "\t\ty = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "\t\tif return_attentions:\n",
    "\t\t\treturn y, att_weights, v\n",
    "\t\treturn y\n",
    "\n",
    "class MultiHeadCrossAttention(nn.Module):\n",
    "\n",
    "\t''' Multi-head cross attention.\n",
    "\tImplements a somewhat optimized version of the cross attention by combining the k, v projections.\n",
    "\t\n",
    "\tInputs:\n",
    "\t\tx_q: query tensor of shape (B, T, C)\n",
    "\t\tx_kv: key and value tensor of shape (B, T, C)\n",
    "\t\tmask: mask tensor of shape broadcastable to (B, T, T)\n",
    "\t'''\n",
    "\n",
    "\tdef __init__(self, n_heads: int, emb_dim: int, bias: bool):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.n_heads = n_heads\n",
    "\t\tself.emb_dim = emb_dim\n",
    "\t\tself.q_projection = nn.Linear(emb_dim, emb_dim, bias=bias)\n",
    "\t\t# combine k, v projections for efficiency\n",
    "\t\tself.kv_projection = nn.Linear(emb_dim, 2 * emb_dim, bias=bias)\n",
    "\t\tself.register_buffer('scale', torch.tensor(emb_dim ** -0.5, dtype=torch.float32))\n",
    "\n",
    "\tdef forward(self, x_q: Tensor, x_kv: Tensor, mask: Tensor):\n",
    "\t\t# proj query for all heads\n",
    "\t\tB, T, C = x_q.shape\n",
    "\t\tq = self.q_projection(x_q)\n",
    "\t\tq = q.view(B, T, self.n_heads, C // self.n_heads).transpose(1, 2)\n",
    "\t\t# proj key & value for all heads\n",
    "\t\tB, T, C = x_kv.shape\n",
    "\t\tk, v = self.kv_projection(x_kv).split(self.emb_dim, dim=2)\n",
    "\t\tk = k.view(B, T, self.n_heads, C // self.n_heads).transpose(1, 2)\n",
    "\t\tv = v.view(B, T, self.n_heads, C // self.n_heads).transpose(1, 2)\n",
    "\t\t# compute attention\n",
    "\t\tatt_weights = (q @ k.transpose(-2, -1)) / self.scale\n",
    "\t\tmask = mask.unsqueeze(1) # apply mask over all heads\n",
    "\t\tatt_weights = att_weights.masked_fill(mask == 0, -1e9)\n",
    "\t\tatt_weights = F.softmax(att_weights, dim=-1)\n",
    "\t\ty = att_weights @ v\n",
    "\t\t# combine heads\n",
    "\t\ty = y.transpose(1, 2).contiguous().view(B, T, C)\n",
    "\t\treturn y\n",
    "\n",
    "class FeedFoward(nn.Module):\n",
    "\n",
    "\tdef __init__(self, emb_dim: int, dropout: float = 0.0):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.net = nn.Sequential(\n",
    "\t\t\tnn.Linear(emb_dim, 4 * emb_dim),\n",
    "\t\t\tnn.ReLU(),\n",
    "\t\t\tnn.Linear(4 * emb_dim, emb_dim),\n",
    "\t\t)\n",
    "\t\tif dropout:\n",
    "\t\t\tself.net.append(nn.Dropout(dropout))\n",
    "\n",
    "\tdef forward(self, x: Tensor):\n",
    "\t\treturn self.net(x)\n",
    "\t\n",
    "class LMHead(nn.Module):\n",
    "\n",
    "\tdef __init__(self, emb_dim: int, vocab_size: int):\n",
    "\t\tsuper().__init__()\n",
    "\t\tself.ln = nn.LayerNorm(emb_dim)\n",
    "\t\tself.logits_head = nn.Linear(emb_dim, vocab_size)\n",
    "\t\n",
    "\tdef forward(self, x: Tensor):\n",
    "\t\tx = self.ln(x)\n",
    "\t\tx = self.logits_head(x)\n",
    "\t\treturn x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.176:  45%|████▌     | 4512/10000 [00:18<00:22, 243.47it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[104], line 22\u001b[0m\n\u001b[0;32m     20\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(dl, total\u001b[39m=\u001b[39mn_steps)\n\u001b[0;32m     21\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 22\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m pbar:\n\u001b[0;32m     23\u001b[0m \t\u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m n_steps:\n\u001b[0;32m     24\u001b[0m \t\t\u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Chen Zerui\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Chen Zerui\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Chen Zerui\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Chen Zerui\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Chen Zerui\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[94], line 12\u001b[0m, in \u001b[0;36mReversionDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[0;32m     11\u001b[0m \tx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mrandint(\u001b[39m0\u001b[39m, \u001b[39m10\u001b[39m, (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mblock_size,), dtype\u001b[39m=\u001b[39mtorch\u001b[39m.\u001b[39mfloat32)\n\u001b[1;32m---> 12\u001b[0m \ty \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39;49mflip(\u001b[39m0\u001b[39;49m)\n\u001b[0;32m     13\u001b[0m \t\u001b[39mreturn\u001b[39;00m x, y\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# train a single multi-head attention layer on the reversion dataset, using mse loss and adamw optimizer\n",
    "n_steps = 10000\n",
    "batch_size = 128\n",
    "block_size = 128\n",
    "n_heads = 1\n",
    "emb_dim = 1\n",
    "lr = 1e-2\n",
    "\n",
    "mha = MultiHeadSelfAttention(n_heads, emb_dim, False, block_size, False).cuda()\n",
    "\n",
    "# init ds & dl\n",
    "ds = ReversionDataset(block_size)\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# init optim\n",
    "optimizer = torch.optim.AdamW(mha.parameters(), lr=lr)\n",
    "\n",
    "# training loop, using tqdm and showing loss at every step\n",
    "pbar = tqdm(dl, total=n_steps)\n",
    "i = 0\n",
    "for x, y in pbar:\n",
    "\tif i > n_steps:\n",
    "\t\tbreak\n",
    "\tx = x.unsqueeze(-1).cuda()\n",
    "\tx_mask = torch.ones(block_size).cuda()\n",
    "\ty = y.unsqueeze(-1).cuda()\n",
    "\tpred = mha(x, x_mask)\n",
    "\tloss = F.mse_loss(pred, y)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\toptimizer.zero_grad()\n",
    "\tpbar.set_description(f'loss: {loss.item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 8.178:  44%|████▍     | 4383/10000 [00:19<00:25, 224.20it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[113], line 23\u001b[0m\n\u001b[0;32m     21\u001b[0m pbar \u001b[39m=\u001b[39m tqdm(dl, total\u001b[39m=\u001b[39mn_steps)\n\u001b[0;32m     22\u001b[0m i \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m---> 23\u001b[0m \u001b[39mfor\u001b[39;00m x, y \u001b[39min\u001b[39;00m pbar:\n\u001b[0;32m     24\u001b[0m \t\u001b[39mif\u001b[39;00m i \u001b[39m>\u001b[39m n_steps:\n\u001b[0;32m     25\u001b[0m \t\t\u001b[39mbreak\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Chen Zerui\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\tqdm\\std.py:1178\u001b[0m, in \u001b[0;36mtqdm.__iter__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m   1175\u001b[0m time \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_time\n\u001b[0;32m   1177\u001b[0m \u001b[39mtry\u001b[39;00m:\n\u001b[1;32m-> 1178\u001b[0m     \u001b[39mfor\u001b[39;00m obj \u001b[39min\u001b[39;00m iterable:\n\u001b[0;32m   1179\u001b[0m         \u001b[39myield\u001b[39;00m obj\n\u001b[0;32m   1180\u001b[0m         \u001b[39m# Update and possibly print the progressbar.\u001b[39;00m\n\u001b[0;32m   1181\u001b[0m         \u001b[39m# Note: does not call self.update(1) for speed optimisation.\u001b[39;00m\n",
      "File \u001b[1;32mc:\\Users\\Chen Zerui\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:628\u001b[0m, in \u001b[0;36m_BaseDataLoaderIter.__next__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    625\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_sampler_iter \u001b[39mis\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n\u001b[0;32m    626\u001b[0m     \u001b[39m# TODO(https://github.com/pytorch/pytorch/issues/76750)\u001b[39;00m\n\u001b[0;32m    627\u001b[0m     \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_reset()  \u001b[39m# type: ignore[call-arg]\u001b[39;00m\n\u001b[1;32m--> 628\u001b[0m data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_next_data()\n\u001b[0;32m    629\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m+\u001b[39m\u001b[39m=\u001b[39m \u001b[39m1\u001b[39m\n\u001b[0;32m    630\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_dataset_kind \u001b[39m==\u001b[39m _DatasetKind\u001b[39m.\u001b[39mIterable \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    631\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m \u001b[39mand\u001b[39;00m \\\n\u001b[0;32m    632\u001b[0m         \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_num_yielded \u001b[39m>\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_IterableDataset_len_called:\n",
      "File \u001b[1;32mc:\\Users\\Chen Zerui\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\dataloader.py:671\u001b[0m, in \u001b[0;36m_SingleProcessDataLoaderIter._next_data\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    669\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_next_data\u001b[39m(\u001b[39mself\u001b[39m):\n\u001b[0;32m    670\u001b[0m     index \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_next_index()  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[1;32m--> 671\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_dataset_fetcher\u001b[39m.\u001b[39;49mfetch(index)  \u001b[39m# may raise StopIteration\u001b[39;00m\n\u001b[0;32m    672\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory:\n\u001b[0;32m    673\u001b[0m         data \u001b[39m=\u001b[39m _utils\u001b[39m.\u001b[39mpin_memory\u001b[39m.\u001b[39mpin_memory(data, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_pin_memory_device)\n",
      "File \u001b[1;32mc:\\Users\\Chen Zerui\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m_MapDatasetFetcher.fetch\u001b[1;34m(self, possibly_batched_index)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "File \u001b[1;32mc:\\Users\\Chen Zerui\\AppData\\Local\\Programs\\Python\\Python310\\lib\\site-packages\\torch\\utils\\data\\_utils\\fetch.py:58\u001b[0m, in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m     56\u001b[0m         data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset\u001b[39m.\u001b[39m__getitems__(possibly_batched_index)\n\u001b[0;32m     57\u001b[0m     \u001b[39melse\u001b[39;00m:\n\u001b[1;32m---> 58\u001b[0m         data \u001b[39m=\u001b[39m [\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mdataset[idx] \u001b[39mfor\u001b[39;00m idx \u001b[39min\u001b[39;00m possibly_batched_index]\n\u001b[0;32m     59\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m     60\u001b[0m     data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mdataset[possibly_batched_index]\n",
      "Cell \u001b[1;32mIn[94], line 11\u001b[0m, in \u001b[0;36mReversionDataset.__getitem__\u001b[1;34m(self, idx)\u001b[0m\n\u001b[0;32m     10\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m__getitem__\u001b[39m(\u001b[39mself\u001b[39m, idx):\n\u001b[1;32m---> 11\u001b[0m \tx \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39;49mrandint(\u001b[39m0\u001b[39;49m, \u001b[39m10\u001b[39;49m, (\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mblock_size,), dtype\u001b[39m=\u001b[39;49mtorch\u001b[39m.\u001b[39;49mfloat32)\n\u001b[0;32m     12\u001b[0m \ty \u001b[39m=\u001b[39m x\u001b[39m.\u001b[39mflip(\u001b[39m0\u001b[39m)\n\u001b[0;32m     13\u001b[0m \t\u001b[39mreturn\u001b[39;00m x, y\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "# train a single multi-head attention layer on the reversion dataset, using mse loss and adamw optimizer\n",
    "n_steps = 10000\n",
    "batch_size = 128\n",
    "block_size = 128\n",
    "n_heads = 1\n",
    "emb_dim = 1\n",
    "lr = 1e-2\n",
    "\n",
    "mha = torch.nn.MultiheadAttention(emb_dim, n_heads, dropout=0.0, bias=False, batch_first=True).cuda()\n",
    "\n",
    "# init ds & dl\n",
    "ds = ReversionDataset(block_size)\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "\n",
    "# init optim\n",
    "optimizer = torch.optim.AdamW(mha.parameters(), lr=lr)\n",
    "\n",
    "# training loop, using tqdm and showing loss at every step\n",
    "pbar = tqdm(dl, total=n_steps)\n",
    "i = 0\n",
    "for x, y in pbar:\n",
    "\tif i > n_steps:\n",
    "\t\tbreak\n",
    "\tx = x.unsqueeze(-1).cuda()\n",
    "\tx_mask = torch.ones(block_size).cuda()\n",
    "\ty = y.unsqueeze(-1).cuda()\n",
    "\tpred, atten_weights = mha(x, x, x)\n",
    "\tloss = F.mse_loss(pred, y)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\toptimizer.zero_grad()\n",
    "\tpbar.set_description(f'loss: {loss.item():.3f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "x\t -0.5083462 -0.5083462 -1.0166924 -1.5250385 -2.5417309 -4.0667696 -6.6085005 -10.67527 -17.28377 -27.95904 -45.24281 -73.20185 -118.44466 -191.64651 -310.09116 -501.73767\n",
      "y\t -0.5083462 -1.0166924 -1.5250385 -2.5417309 -4.0667696 -6.6085005 -10.67527 -17.28377 -27.95904 -45.24281 -73.20185 -118.44466 -191.64651 -310.09116 -501.73767 -811.82886\n",
      "y_pred\t -0.8225174 -0.8225174 -1.1174242 -1.5367235 -2.546073 -5.310747 -10.554775 -17.272297 -27.96559 -45.238453 -73.20404 -118.4425 -191.64653 -310.08905 -501.73557 -811.8246\n",
      "v\t -0.8225174 -0.8225174 -1.6450348 -2.467552 -4.1125865 -6.580139 -10.692726 -17.272865 -27.96559 -45.238453 -73.20404 -118.4425 -191.64653 -310.08905 -501.73557 -811.8246\n"
     ]
    }
   ],
   "source": [
    "# test the mha layer on the fibonacci dataset\n",
    "ds = FibonacciDataset(16)\n",
    "x, y = ds[0]\n",
    "x = x.unsqueeze(0).unsqueeze(-1).cuda()\n",
    "x_mask = torch.ones(x.shape[1], dtype=torch.long).cuda()\n",
    "y_pred, attn, v = mha(x, x_mask, return_attentions=True)\n",
    "print('x\\t', *x.view(16).cpu().numpy())\n",
    "print('y\\t', *y.view(16).numpy())\n",
    "print('y_pred\\t', *y_pred.detach().view(16).cpu().numpy())\n",
    "print('v\\t', *v.detach().view(16).cpu().numpy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# plot the attention weights as heatmap, using seaborn\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "sns.heatmap(attn[0, 0].detach().cpu().numpy(), cmap='Blues')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "loss: 0.405: : 10001it [00:47, 212.63it/s]                            \n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "n_steps = 10000\n",
    "batch_size = 128\n",
    "mha = MultiHeadSelfAttention(1, 1, False, 16, True).cuda()\n",
    "\n",
    "# train a single mha layer on the fibonacci dataset for n_steps, using mse loss and adamw optimizer\n",
    "ds = FibonacciDataset(16)\n",
    "dl = torch.utils.data.DataLoader(ds, batch_size=batch_size, shuffle=False)\n",
    "optimizer = torch.optim.AdamW(mha.parameters(), lr=5e-3)\n",
    "\n",
    "pbar = tqdm(dl, total=n_steps)\n",
    "i = 0\n",
    "for x, y in pbar:\n",
    "\tif i > n_steps:\n",
    "\t\tbreak\n",
    "\tx = x.unsqueeze(-1).cuda()\n",
    "\tx_mask = subsequent_mask(x.shape[1]).cuda()\n",
    "\ty = y.unsqueeze(-1).cuda()\n",
    "\tpred = mha(x, x_mask)\n",
    "\tloss = F.mse_loss(pred, y)\n",
    "\tloss.backward()\n",
    "\toptimizer.step()\n",
    "\toptimizer.zero_grad()\n",
    "\tpbar.set_description(f'loss: {loss.item():.3f}')\n",
    "\ti += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[-4.2840],\n",
       "        [-0.0503],\n",
       "        [ 1.6180]])"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mha.qkv_projection.weight.detach().cpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.73136276"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "-4.7116 * -3.5511"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
