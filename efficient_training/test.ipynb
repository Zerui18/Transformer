{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from datasets import Dataset\n",
    "\n",
    "seq_len, dataset_size = 512, 128\n",
    "dummy_data = {\n",
    "    \"input_ids\": np.random.randint(100, 30000, (dataset_size, seq_len)),\n",
    "    \"labels\": np.random.randint(0, 1, (dataset_size)),\n",
    "}\n",
    "ds = Dataset.from_dict(dummy_data)\n",
    "ds.set_format(\"pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pynvml import *\n",
    "\n",
    "def print_gpu_utilization():\n",
    "    nvmlInit()\n",
    "    handle = nvmlDeviceGetHandleByIndex(0)\n",
    "    info = nvmlDeviceGetMemoryInfo(handle)\n",
    "    print(f\"GPU memory occupied: {info.used//1024**2} MB.\")\n",
    "\n",
    "\n",
    "def print_summary(result):\n",
    "    print(f\"Time: {result.metrics['train_runtime']:.2f}\")\n",
    "    print(f\"Samples/second: {result.metrics['train_samples_per_second']:.2f}\")\n",
    "    print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 632 MB.\n"
     ]
    }
   ],
   "source": [
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 850 MB.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "a = torch.tensor(1).cuda()\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Some weights of the model checkpoint at bert-large-uncased were not used when initializing BertForSequenceClassification: ['cls.predictions.transform.dense.weight', 'cls.predictions.bias', 'cls.predictions.transform.LayerNorm.bias', 'cls.seq_relationship.bias', 'cls.predictions.decoder.weight', 'cls.seq_relationship.weight', 'cls.predictions.transform.LayerNorm.weight', 'cls.predictions.transform.dense.bias']\n",
      "- This IS expected if you are initializing BertForSequenceClassification from the checkpoint of a model trained on another task or with another architecture (e.g. initializing a BertForSequenceClassification model from a BertForPreTraining model).\n",
      "- This IS NOT expected if you are initializing BertForSequenceClassification from the checkpoint of a model that you expect to be exactly identical (initializing a BertForSequenceClassification model from a BertForSequenceClassification model).\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at bert-large-uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU memory occupied: 2138 MB.\n"
     ]
    }
   ],
   "source": [
    "from transformers import AutoModelForSequenceClassification\n",
    "\n",
    "\n",
    "model = AutoModelForSequenceClassification.from_pretrained(\"bert-large-uncased\").to(\"cuda\")\n",
    "print_gpu_utilization()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3.8333333333333335"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(2219-931) / 336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "default_args = {\n",
    "    \"output_dir\": \"tmp\",\n",
    "    \"evaluation_strategy\": \"max_steps\",\n",
    "    \"num_train_epochs\": 1,\n",
    "    \"log_level\": \"error\",\n",
    "    \"report_to\": \"none\",\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "from transformers import TrainingArguments, Trainer, logging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zerui/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b901c5212fbd4362bbb1ff25819298b7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/4 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 14.0111, 'train_samples_per_second': 9.136, 'train_steps_per_second': 0.285, 'train_loss': 0.5233250856399536, 'epoch': 1.0}\n",
      "Time: 14.01\n",
      "Samples/second: 9.14\n",
      "GPU memory occupied: 8512 MB.\n"
     ]
    }
   ],
   "source": [
    "## GRAD ACCUM + CKPT (4)\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=16, gradient_accumulation_steps=4, gradient_checkpointing=True, **default_args)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zerui/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "d436db359c3b4573ae44415a309d7be7",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 18.1932, 'train_samples_per_second': 7.036, 'train_steps_per_second': 7.036, 'train_loss': 0.023147890344262123, 'epoch': 1.0}\n",
      "Time: 18.19\n",
      "Samples/second: 7.04\n",
      "GPU memory occupied: 6770 MB.\n"
     ]
    }
   ],
   "source": [
    "# VANILLA\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=1, **default_args)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d8c055edaef47358f6adea88d5e10ae",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 22.8572, 'train_samples_per_second': 5.6, 'train_steps_per_second': 5.6, 'train_loss': 0.063768669962883, 'epoch': 1.0}\n",
      "Time: 22.86\n",
      "Samples/second: 5.60\n",
      "GPU memory occupied: 4325 MB.\n"
     ]
    }
   ],
   "source": [
    "## ADAFACTOR\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=1, optim=\"adafactor\", **default_args)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e24625314ed346959a9574b95453a64b",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/64 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 16.8882, 'train_samples_per_second': 7.579, 'train_steps_per_second': 3.79, 'train_loss': 0.05527115240693092, 'epoch': 1.0}\n",
      "Time: 16.89\n",
      "Samples/second: 7.58\n",
      "GPU memory occupied: 6014 MB.\n"
     ]
    }
   ],
   "source": [
    "## ADAFACTOR X2\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=2, optim=\"adafactor\", **default_args)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "93f8e7487ec1412b8f689eb50b44ce8c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 13.6542, 'train_samples_per_second': 9.374, 'train_steps_per_second': 2.344, 'train_loss': 0.04318753629922867, 'epoch': 1.0}\n",
      "Time: 13.65\n",
      "Samples/second: 9.37\n",
      "GPU memory occupied: 9730 MB.\n"
     ]
    }
   ],
   "source": [
    "## ADAFACTOR X4\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=4, optim=\"adafactor\", **default_args)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-12 16:28:43,489] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/zerui/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/zerui/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load cpu_adam op: 2.2330217361450195 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/zerui/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/zerui/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load utils op: 0.007245540618896484 seconds\n",
      "Rank: 0 partition count [1] and sizes[(335143938, False)] \n",
      "Time to load utils op: 0.0004546642303466797 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/zerui/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "f0fb4021a9a24b76bad409561d28720d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 85.6566, 'train_samples_per_second': 1.494, 'train_steps_per_second': 1.494, 'train_loss': 0.03127874433994293, 'epoch': 1.0}\n",
      "Time: 85.66\n",
      "Samples/second: 1.49\n",
      "GPU memory occupied: 7569 MB.\n"
     ]
    }
   ],
   "source": [
    "## DEEPSPEED ZERO 2\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9994\"\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=1, deepspeed='ds_config_zero2.json', **default_args)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/zerui/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Creating extension directory /home/zerui/.cache/torch_extensions/py310_cu118/cpu_adam...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/zerui/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/3] /usr/local/cuda/bin/nvcc  -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/zerui/.local/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda/include -isystem /home/zerui/.local/lib/python3.10/site-packages/torch/include -isystem /home/zerui/.local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/zerui/.local/lib/python3.10/site-packages/torch/include/TH -isystem /home/zerui/.local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -D__CUDA_NO_HALF_OPERATORS__ -D__CUDA_NO_HALF_CONVERSIONS__ -D__CUDA_NO_BFLOAT16_CONVERSIONS__ -D__CUDA_NO_HALF2_OPERATORS__ --expt-relaxed-constexpr -gencode=arch=compute_86,code=compute_86 -gencode=arch=compute_86,code=sm_86 --compiler-options '-fPIC' -O3 --use_fast_math -std=c++14 -U__CUDA_NO_HALF_OPERATORS__ -U__CUDA_NO_HALF_CONVERSIONS__ -U__CUDA_NO_HALF2_OPERATORS__ -gencode=arch=compute_86,code=sm_86 -gencode=arch=compute_86,code=compute_86 -c /home/zerui/.local/lib/python3.10/site-packages/deepspeed/ops/csrc/common/custom_cuda_kernel.cu -o custom_cuda_kernel.cuda.o \n",
      "[2/3] c++ -MMD -MF cpu_adam.o.d -DTORCH_EXTENSION_NAME=cpu_adam -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -I/home/zerui/.local/lib/python3.10/site-packages/deepspeed/ops/csrc/includes -I/usr/local/cuda/include -isystem /home/zerui/.local/lib/python3.10/site-packages/torch/include -isystem /home/zerui/.local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/zerui/.local/lib/python3.10/site-packages/torch/include/TH -isystem /home/zerui/.local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/local/cuda/include -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -O3 -std=c++14 -g -Wno-reorder -L/usr/local/cuda/lib64 -lcudart -lcublas -g -march=native -fopenmp -D__AVX256__ -c /home/zerui/.local/lib/python3.10/site-packages/deepspeed/ops/csrc/adam/cpu_adam.cpp -o cpu_adam.o \n",
      "[3/3] c++ cpu_adam.o custom_cuda_kernel.cuda.o -shared -lcurand -L/home/zerui/.local/lib/python3.10/site-packages/torch/lib -lc10 -lc10_cuda -ltorch_cpu -ltorch_cuda -ltorch -ltorch_python -L/usr/local/cuda/lib64 -lcudart -o cpu_adam.so\n",
      "Time to load cpu_adam op: 19.759360551834106 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module cpu_adam...\n",
      "Using /home/zerui/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Creating extension directory /home/zerui/.cache/torch_extensions/py310_cu118/utils...\n",
      "Emitting ninja build file /home/zerui/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[1/2] c++ -MMD -MF flatten_unflatten.o.d -DTORCH_EXTENSION_NAME=utils -DTORCH_API_INCLUDE_EXTENSION_H -DPYBIND11_COMPILER_TYPE=\\\"_gcc\\\" -DPYBIND11_STDLIB=\\\"_libstdcpp\\\" -DPYBIND11_BUILD_ABI=\\\"_cxxabi1011\\\" -isystem /home/zerui/.local/lib/python3.10/site-packages/torch/include -isystem /home/zerui/.local/lib/python3.10/site-packages/torch/include/torch/csrc/api/include -isystem /home/zerui/.local/lib/python3.10/site-packages/torch/include/TH -isystem /home/zerui/.local/lib/python3.10/site-packages/torch/include/THC -isystem /usr/include/python3.10 -D_GLIBCXX_USE_CXX11_ABI=0 -fPIC -std=c++17 -c /home/zerui/.local/lib/python3.10/site-packages/deepspeed/ops/csrc/utils/flatten_unflatten.cpp -o flatten_unflatten.o \n",
      "[2/2] c++ flatten_unflatten.o -shared -L/home/zerui/.local/lib/python3.10/site-packages/torch/lib -lc10 -ltorch_cpu -ltorch -ltorch_python -o utils.so\n",
      "Time to load utils op: 9.119560480117798 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parameter Offload: Total persistent parameters: 326658 in 246 params\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/zerui/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n",
      "/home/zerui/.local/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:2541: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to load utils op: 0.00043702125549316406 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zerui/.local/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:3009: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 139.6129, 'train_samples_per_second': 0.917, 'train_steps_per_second': 0.917, 'train_loss': 0.01930386945605278, 'epoch': 1.0}\n",
      "Time: 139.61\n",
      "Samples/second: 0.92\n",
      "GPU memory occupied: 4786 MB.\n"
     ]
    }
   ],
   "source": [
    "## DEEPSPEED ZERO 3\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9994\"\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=1, deepspeed='ds_config_zero3.json', **default_args)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2023-02-12 16:21:23,734] [INFO] [comm.py:657:init_distributed] Initializing TorchBackend in DeepSpeed with backend nccl\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/zerui/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Detected CUDA files, patching ldflags\n",
      "Emitting ninja build file /home/zerui/.cache/torch_extensions/py310_cu118/cpu_adam/build.ninja...\n",
      "Building extension module cpu_adam...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module cpu_adam...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load cpu_adam op: 2.217463493347168 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/zerui/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "Emitting ninja build file /home/zerui/.cache/torch_extensions/py310_cu118/utils/build.ninja...\n",
      "Building extension module utils...\n",
      "Allowing ninja to set a default number of workers... (overridable by setting the environment variable MAX_JOBS=N)\n",
      "Loading extension module utils...\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ninja: no work to do.\n",
      "Time to load utils op: 0.00684046745300293 seconds\n",
      "Parameter Offload: Total persistent parameters: 326658 in 246 params\n",
      "Time to load utils op: 0.0005059242248535156 seconds\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using /home/zerui/.cache/torch_extensions/py310_cu118 as PyTorch extensions root...\n",
      "No modifications detected for re-loaded extension module utils, skipping build step...\n",
      "Loading extension module utils...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "b1dce0d658ca438d8d666d023f14bbfb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zerui/.local/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:2541: UserWarning: torch.distributed._all_gather_base is a private function and will be deprecated. Please use torch.distributed.all_gather_into_tensor instead.\n",
      "  warnings.warn(\n",
      "/home/zerui/.local/lib/python3.10/site-packages/torch/distributed/distributed_c10d.py:3009: UserWarning: torch.distributed._reduce_scatter_base is a private function and will be deprecated. Please use torch.distributed.reduce_scatter_tensor instead.\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 39.3838, 'train_samples_per_second': 3.25, 'train_steps_per_second': 0.813, 'train_loss': 0.07862478494644165, 'epoch': 1.0}\n",
      "Time: 39.38\n",
      "Samples/second: 3.25\n",
      "GPU memory occupied: 10124 MB.\n"
     ]
    }
   ],
   "source": [
    "## DEEPSPEED ZERO 3 X 4\n",
    "\n",
    "import os\n",
    "\n",
    "os.environ[\"MASTER_ADDR\"] = \"localhost\"\n",
    "os.environ[\"MASTER_PORT\"] = \"9994\"\n",
    "os.environ[\"RANK\"] = \"0\"\n",
    "os.environ[\"LOCAL_RANK\"] = \"0\"\n",
    "os.environ[\"WORLD_SIZE\"] = \"1\"\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=4, deepspeed='ds_config_zero3.json', **default_args)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### FP Precision"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zerui/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "38899782c906452d9af79007620583e1",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 15.6338, 'train_samples_per_second': 8.187, 'train_steps_per_second': 8.187, 'train_loss': 0.03858725726604462, 'epoch': 1.0}\n",
      "Time: 15.63\n",
      "Samples/second: 8.19\n",
      "GPU memory occupied: 6768 MB.\n"
     ]
    }
   ],
   "source": [
    "# TF32\n",
    "\n",
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=1, **default_args)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zerui/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "5e14b09b9f1b4ed5941d15bf07881a3d",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 14.8333, 'train_samples_per_second': 8.629, 'train_steps_per_second': 8.629, 'train_loss': 0.03560449928045273, 'epoch': 1.0}\n",
      "Time: 14.83\n",
      "Samples/second: 8.63\n",
      "GPU memory occupied: 6876 MB.\n"
     ]
    }
   ],
   "source": [
    "# FP 16\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=1, fp16=True, **default_args)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zerui/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "692c474c3df0426cb679357cf8dc08a3",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/128 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 15.1285, 'train_samples_per_second': 8.461, 'train_steps_per_second': 8.461, 'train_loss': 0.038383085280656815, 'epoch': 1.0}\n",
      "Time: 15.13\n",
      "Samples/second: 8.46\n",
      "GPU memory occupied: 6876 MB.\n"
     ]
    }
   ],
   "source": [
    "# TF32 & FP16\n",
    "\n",
    "import torch\n",
    "torch.backends.cuda.matmul.allow_tf32 = True\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=1, tf32=True, fp16=True, **default_args)\n",
    "\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Gradient Accum + Ckpt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 14.1982, 'train_samples_per_second': 9.015, 'train_steps_per_second': 2.254, 'train_loss': 5.175313162908424e-06, 'epoch': 1.0}\n",
      "Time: 14.20\n",
      "Samples/second: 9.02\n",
      "GPU memory occupied: 7774 MB.\n"
     ]
    }
   ],
   "source": [
    "# GRAD ACCUM ONLY\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=1, gradient_accumulation_steps=4, **default_args)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zerui/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ccc3ba8bfb294fd5ad20948246970c75",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/32 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 18.4171, 'train_samples_per_second': 6.95, 'train_steps_per_second': 1.738, 'train_loss': 0.03817403316497803, 'epoch': 1.0}\n",
      "Time: 18.42\n",
      "Samples/second: 6.95\n",
      "GPU memory occupied: 6374 MB.\n"
     ]
    }
   ],
   "source": [
    "## GRAD ACCUM + CKPT\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=1, gradient_accumulation_steps=4, gradient_checkpointing=True, **default_args)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zerui/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "24aada27aafd4618aac34723703ac290",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 16.4072, 'train_samples_per_second': 7.801, 'train_steps_per_second': 0.975, 'train_loss': 0.15510064363479614, 'epoch': 1.0}\n",
      "Time: 16.41\n",
      "Samples/second: 7.80\n",
      "GPU memory occupied: 6500 MB.\n"
     ]
    }
   ],
   "source": [
    "## GRAD ACCUM + CKPT (2)\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=2, gradient_accumulation_steps=4, gradient_checkpointing=True, **default_args)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/zerui/.local/lib/python3.10/site-packages/transformers/optimization.py:306: FutureWarning: This implementation of AdamW is deprecated and will be removed in a future version. Use the PyTorch implementation torch.optim.AdamW instead, or set `no_deprecation_warning=True` to disable this warning\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8d41f75c25194a68911605c08c82c582",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/16 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'train_runtime': 15.5595, 'train_samples_per_second': 8.226, 'train_steps_per_second': 1.028, 'train_loss': 0.11093101650476456, 'epoch': 1.0}\n",
      "Time: 15.56\n",
      "Samples/second: 8.23\n",
      "GPU memory occupied: 6859 MB.\n"
     ]
    }
   ],
   "source": [
    "## GRAD ACCUM + CKPT (4)\n",
    "\n",
    "training_args = TrainingArguments(per_device_train_batch_size=4, gradient_accumulation_steps=2, gradient_checkpointing=True, **default_args)\n",
    "trainer = Trainer(model=model, args=training_args, train_dataset=ds)\n",
    "result = trainer.train()\n",
    "print_summary(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "16.860119047619047"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(7884 - 2219) / 336"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[p.dtype for p in model.parameters()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "66.448992"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "n_params * 4 / 1e6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import TextGenerationDataset\n",
    "from model import TransformerModelLN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sentencepiece as sp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = sp.SentencePieceProcessor(model_file='shakespeare_15000.model')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = TransformerModelLN.load_inference_model_from_compiled_checkpoint('gpt-shakespeare-sp15000.pt', vocab_size=tokenizer.vocab_size(), block_len=512, learning_rate=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.cuda()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.generate('What shall we do after returning from war?', tokenizer, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "916dbcbb3f70747c44a77c7bcd40155683ae19c65e1c03b4aa3499c5328201f1"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
